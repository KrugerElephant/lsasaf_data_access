{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee75bd4d-0e34-4504-bf98-08e8c8b512d8",
   "metadata": {},
   "source": [
    "<p>Example script to extract 1 month of hourly MLST MSG product over a domain</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "211e0dcc-a8c3-4c10-b243-f77fb9d86b01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import thredds_lsasaf_utils as tlu\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from shapely.geometry import Point\n",
    "from shapely import wkt\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.genmod.families import Gaussian\n",
    "from statsmodels.genmod.families.links import Power\n",
    "from statsmodels.genmod.families import Gamma\n",
    "from statsmodels.genmod.families.links import log, identity\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7de56f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(dstart, dend, product_freq, LatLonBox):\n",
    "\n",
    "    # Change here your user credentials\n",
    "    server_user = \"karpagam\"\n",
    "    server_passwd = \"chip-chop-2025\"\n",
    "\n",
    "    # Change here the product details\n",
    "    # Go to https://thredds.lsasvcs.ipma.pt/thredds/catalog/catalog.html\n",
    "    # Navigate selecting satelite, product, format, and data to find the product_path and product file name\n",
    "    # This is an example for the MSG MLST\n",
    "\n",
    "    product_path = \"/MSG/MLST/NETCDF/\"\n",
    "    product_fname = \"NETCDF4_LSASAF_MSG_LST_MSG-Disk\"\n",
    "    NcvarsLoad = ['LST'] # list of netcdf variables to load from remote files\n",
    "\n",
    "    # Initialize product details\n",
    "    product = tlu.lsa_product(product_path,product_fname)\n",
    "    product.user = server_user\n",
    "    product.passwd = server_passwd\n",
    "\n",
    "    # list of slots to be processed:\n",
    "    slot_list = tlu.gen_slot_list(dstart, dend, product_freq)\n",
    "    print(f\"Will load:{len(slot_list)} files: {slot_list[0]} to {slot_list[-1]}\")\n",
    "\n",
    "    # Load data\n",
    "    ds_full = tlu.load_product_slots_domain(product, slot_list, NcvarsLoad, LatLonBox=LatLonBox)\n",
    "\n",
    "    # Extract the data array (assuming the variable name is 'temperature')\n",
    "    data_array = ds_full['LST']\n",
    "\n",
    "    # Step 1: Extract the temperature DataArray\n",
    "    temperature_da = ds_full['LST']\n",
    "\n",
    "    # Step 2: Stack dimensions (combine 'time', 'lat', and 'lon')\n",
    "    stacked = temperature_da.stack(points=('time', 'lat', 'lon'))\n",
    "\n",
    "    # Step 3: Reset the index and convert to DataFrame\n",
    "    df = stacked.reset_index(['time', 'lat', 'lon']).to_dataframe(name='temperature').reset_index(drop=True)\n",
    "\n",
    "    # Step 4: Add an 'hour' column 'day', 'month' and 'year'\n",
    "    df['hour'] = df['time'].dt.hour\n",
    "    df['day'] = df['time'].dt.day\n",
    "    df['month'] = df['time'].dt.month\n",
    "    df['year'] = df['time'].dt.year\n",
    "\n",
    "    # Create geometry from latitude and longitude\n",
    "    geometry = [Point(xy) for xy in zip(df['lon'], df['lat'])]\n",
    "\n",
    "    # Convert to GeoDataFrame\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=geometry)\n",
    "\n",
    "    # Set the Coordinate Reference System (CRS) - assuming WGS84 (EPSG:4326)\n",
    "    gdf.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21f9ee35-4f88-4099-be09-845dcec6390f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (3295979398.py, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 23\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f'GeoDataFrame without 'geometry' saved as {csv_filename}')\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "# Time period to process\n",
    "dstart = dt.datetime(2023, 6, 1, 0, 0, 0) # start slot\n",
    "dend = dt.datetime(2023, 6, 1, 23, 0, 0)   # end slot\n",
    "\n",
    "# Frequency\n",
    "product_freq = \"h\" # hourly frequency\n",
    "\n",
    "# Define latitude/longitude domain to load [lat_min,lat_max,lon_min,lon_max,]\n",
    "LatLonBox = [41.6899140207028722, 42.0902931428349447, 12.2299337725884012, 12.7300258912577391] # Rome\n",
    "\n",
    "# Download data\n",
    "gdf = download_data(dstart, dend, product_freq, LatLonBox)\n",
    "\n",
    "# Drop the 'geometry' column\n",
    "df_no_geometry = gdf.drop(columns=['geometry'])\n",
    "\n",
    "# Create filename\n",
    "csv_filename = f'{dstart.year}-{dstart.month}-{dstart.day}_{dend.year}-{dend.month}-{dend.day}.csv'\n",
    "\n",
    "# Save to a CSV file\n",
    "df_no_geometry.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(f'GeoDataFrame without geometry saved as {csv_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "268b3c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fused_data(filename):\n",
    "\n",
    "    # Replace 'your_file.csv' with the path to your CSV file\n",
    "    file_path = filename\n",
    "\n",
    "    # Load the CSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Ensure the CSV contains 'lat' and 'lon' columns\n",
    "    if 'lat' not in df.columns or 'lon' not in df.columns:\n",
    "        raise ValueError(\"The CSV file must contain 'lat' and 'lon' columns\")\n",
    "\n",
    "    # Create a GeoDataFrame\n",
    "    geometry = [Point(xy) for xy in zip(df['lon'], df['lat'])]\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=geometry)\n",
    "\n",
    "    # Set the coordinate reference system (CRS) if known, e.g., WGS84 (EPSG:4326)\n",
    "    gdf.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cb3dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the pickle file\n",
    "with open('landuse_profile.pkl', 'rb') as file:\n",
    "    loaded_geo_lulc_dict = pickle.load(file)\n",
    "\n",
    "print(\"Loaded landuse profile:\", loaded_geo_lulc_dict)\n",
    "\n",
    "# Create GeoDataFrame from dictionary\n",
    "lulc_gdf = gpd.GeoDataFrame(\n",
    "    list(loaded_geo_lulc_dict.items()),\n",
    "    columns=['geometry', 'lulc_values'],\n",
    "    geometry='geometry'\n",
    ")\n",
    "lulc_gdf.set_crs(gdf.crs, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c7c232",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_point = gdf['geometry'].iloc[0]\n",
    "print(\"Sample GeoDataFrame Point:\", sample_point)\n",
    "print(\"Is this point in the dictionary?\", sample_point in loaded_geo_lulc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3a9f41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round coordinates to a consistent precision (e.g., 6 decimal places)\n",
    "def round_geometry(geom, precision=6):\n",
    "    return Point(round(geom.x, precision), round(geom.y, precision))\n",
    "\n",
    "# Update GeoDataFrame geometry\n",
    "gdf['geometry'] = gdf['geometry'].apply(lambda geom: round_geometry(geom))\n",
    "\n",
    "# Update LULC dictionary keys\n",
    "loaded_geo_lulc_dict = {\n",
    "    round_geometry(key): value for key, value in loaded_geo_lulc_dict.items()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dbfbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map LULC values to the GeoDataFrame using the geometry column\n",
    "gdf['lulc_values'] = gdf['geometry'].map(loaded_geo_lulc_dict)\n",
    "\n",
    "# Display the updated GeoDataFrame\n",
    "print(gdf.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15167e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add the lulc columns from the pickle file to the geopandas dataframe, using the point geometry as the key\n",
    "# Ensure geometry column matches the keys in the dictionary\n",
    "# If the dictionary keys are WKT strings, convert them to geometry objects for comparison\n",
    "# loaded_geo_lulc_dict = {Point(wkt.loads(k)): v for k, v in loaded_geo_lulc_dict.items()}\n",
    "\n",
    "# Extract the LULC column names from the dictionary values (assuming uniform structure)\n",
    "lulc_columns = [f'lulc_{i+1}' for i in range(len(next(iter(loaded_geo_lulc_dict.values()))))]\n",
    "\n",
    "# Add LULC columns to GeoDataFrame\n",
    "for idx, geom in enumerate(gdf['geometry']):\n",
    "    lulc_values = loaded_geo_lulc_dict.get(geom, [None] * len(lulc_columns))\n",
    "    for col, value in zip(lulc_columns, lulc_values):\n",
    "        gdf.loc[idx, col] = value\n",
    "\n",
    "# Display the updated GeoDataFrame\n",
    "print(gdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3597e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert geometry to WKT format\n",
    "gdf['geometry'] = gdf['geometry'].apply(lambda geom: geom.wkt)\n",
    "\n",
    "# Save to CSV\n",
    "output_csv_path = f'fused_{csv_filename}'\n",
    "gdf.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"GeoDataFrame saved to {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fe5953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure the 'time' column is in datetime format\n",
    "gdf['time'] = pd.to_datetime(gdf['time'])\n",
    "\n",
    "# Sort the GeoDataFrame by time for proper plotting\n",
    "gdf = gdf.sort_values('time')\n",
    "\n",
    "# Plot temperature over time\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(gdf['time'], gdf['temperature'], label='Temperature', color='blue')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Temperature Time Series')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Temperature')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
