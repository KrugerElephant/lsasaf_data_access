{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee75bd4d-0e34-4504-bf98-08e8c8b512d8",
   "metadata": {},
   "source": [
    "<p>Example script to extract 1 month of hourly MLST MSG product over a domain</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "211e0dcc-a8c3-4c10-b243-f77fb9d86b01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import thredds_lsasaf_utils as tlu\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from shapely.geometry import Point\n",
    "from shapely import wkt\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.genmod.families import Gaussian\n",
    "from statsmodels.genmod.families.links import Power\n",
    "from statsmodels.genmod.families import Gamma\n",
    "from statsmodels.genmod.families.links import log, identity\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7de56f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(dstart, dend, product_freq, LatLonBox):\n",
    "\n",
    "    # Change here your user credentials\n",
    "    server_user = \"karpagam\"\n",
    "    server_passwd = \"chip-chop-2025\"\n",
    "\n",
    "    # Change here the product details\n",
    "    # Go to https://thredds.lsasvcs.ipma.pt/thredds/catalog/catalog.html\n",
    "    # Navigate selecting satelite, product, format, and data to find the product_path and product file name\n",
    "    # This is an example for the MSG MLST\n",
    "\n",
    "    product_path = \"/MSG/MLST/NETCDF/\"\n",
    "    product_fname = \"NETCDF4_LSASAF_MSG_LST_MSG-Disk\"\n",
    "    NcvarsLoad = ['LST'] # list of netcdf variables to load from remote files\n",
    "\n",
    "    # Initialize product details\n",
    "    product = tlu.lsa_product(product_path,product_fname)\n",
    "    product.user = server_user\n",
    "    product.passwd = server_passwd\n",
    "\n",
    "    # list of slots to be processed:\n",
    "    slot_list = tlu.gen_slot_list(dstart, dend, product_freq)\n",
    "    print(f\"Will load:{len(slot_list)} files: {slot_list[0]} to {slot_list[-1]}\")\n",
    "\n",
    "    # Load data\n",
    "    ds_full = tlu.load_product_slots_domain(product, slot_list, NcvarsLoad, LatLonBox=LatLonBox)\n",
    "\n",
    "    # Extract the data array (assuming the variable name is 'temperature')\n",
    "    data_array = ds_full['LST']\n",
    "\n",
    "    # Step 1: Extract the temperature DataArray\n",
    "    temperature_da = ds_full['LST']\n",
    "\n",
    "    # Step 2: Stack dimensions (combine 'time', 'lat', and 'lon')\n",
    "    stacked = temperature_da.stack(points=('time', 'lat', 'lon'))\n",
    "\n",
    "    # Step 3: Reset the index and convert to DataFrame\n",
    "    df = stacked.reset_index(['time', 'lat', 'lon']).to_dataframe(name='temperature').reset_index(drop=True)\n",
    "\n",
    "    # Step 4: Add an 'hour' column 'day', 'month' and 'year'\n",
    "    df['hour'] = df['time'].dt.hour\n",
    "    df['day'] = df['time'].dt.day\n",
    "    df['month'] = df['time'].dt.month\n",
    "    df['year'] = df['time'].dt.year\n",
    "\n",
    "    # Create geometry from latitude and longitude\n",
    "    geometry = [Point(xy) for xy in zip(df['lon'], df['lat'])]\n",
    "\n",
    "    # Convert to GeoDataFrame\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=geometry)\n",
    "\n",
    "    # Set the Coordinate Reference System (CRS) - assuming WGS84 (EPSG:4326)\n",
    "    gdf.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f9ee35-4f88-4099-be09-845dcec6390f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change here your user credentials\n",
    "# server_user = \"karpagam\"\n",
    "# server_passwd = \"chip-chop-2025\"\n",
    "\n",
    "# # Change here the product details\n",
    "# # Go to https://thredds.lsasvcs.ipma.pt/thredds/catalog/catalog.html\n",
    "# # Navigate selecting satelite, product, format, and data to find the product_path and product file name\n",
    "# # This is an example for the MSG MLST\n",
    "# product_path = \"/MSG/MLST/NETCDF/\"\n",
    "# product_fname = \"NETCDF4_LSASAF_MSG_LST_MSG-Disk\"\n",
    "# NcvarsLoad = ['LST'] # list of netcdf variables to load from remote files\n",
    "\n",
    "# time period to process\n",
    "dstart = dt.datetime(2024, 6, 1, 0, 0, 0) # start slot\n",
    "dend = dt.datetime(2024, 8, 31, 23, 0, 0)   # end slot\n",
    "product_freq = \"h\" # hourly frequency\n",
    "\n",
    "# Define latitude/longitude domain to load [lat_min,lat_max,lon_min,lon_max,]\n",
    "LatLonBox = [41.6899140207028722, 42.0902931428349447, 12.2299337725884012, 12.7300258912577391] # Rome\n",
    "\n",
    "# gdf = download_data(dstart, dend, product_freq, LatLonBox)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "268b3c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fused_data(filename):\n",
    "\n",
    "    # Replace 'your_file.csv' with the path to your CSV file\n",
    "    file_path = filename\n",
    "\n",
    "    # Load the CSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Ensure the CSV contains 'lat' and 'lon' columns\n",
    "    if 'lat' not in df.columns or 'lon' not in df.columns:\n",
    "        raise ValueError(\"The CSV file must contain 'lat' and 'lon' columns\")\n",
    "\n",
    "    # Create a GeoDataFrame\n",
    "    geometry = [Point(xy) for xy in zip(df['lon'], df['lat'])]\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=geometry)\n",
    "\n",
    "    # Set the coordinate reference system (CRS) if known, e.g., WGS84 (EPSG:4326)\n",
    "    gdf.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "600d3db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = read_fused_data('fused_geo_data_june_to_august.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a036938",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad837355",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the pickle file\n",
    "# with open('landuse_profile.pkl', 'rb') as file:\n",
    "#     loaded_geo_lulc_dict = pickle.load(file)\n",
    "\n",
    "# print(\"Loaded landuse profile:\", loaded_geo_lulc_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cb3dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GeoDataFrame from dictionary\n",
    "# lulc_gdf = gpd.GeoDataFrame(\n",
    "#     list(loaded_geo_lulc_dict.items()),\n",
    "#     columns=['geometry', 'lulc_values'],\n",
    "#     geometry='geometry'\n",
    "# )\n",
    "# lulc_gdf.set_crs(gdf.crs, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c7c232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_point = gdf['geometry'].iloc[0]\n",
    "# print(\"Sample GeoDataFrame Point:\", sample_point)\n",
    "# print(\"Is this point in the dictionary?\", sample_point in loaded_geo_lulc_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3a9f41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Round coordinates to a consistent precision (e.g., 6 decimal places)\n",
    "# def round_geometry(geom, precision=6):\n",
    "#     return Point(round(geom.x, precision), round(geom.y, precision))\n",
    "\n",
    "# # Update GeoDataFrame geometry\n",
    "# gdf['geometry'] = gdf['geometry'].apply(lambda geom: round_geometry(geom))\n",
    "\n",
    "# # Update LULC dictionary keys\n",
    "# loaded_geo_lulc_dict = {\n",
    "#     round_geometry(key): value for key, value in loaded_geo_lulc_dict.items()\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dbfbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Map LULC values to the GeoDataFrame using the geometry column\n",
    "# gdf['lulc_values'] = gdf['geometry'].map(loaded_geo_lulc_dict)\n",
    "\n",
    "# # Display the updated GeoDataFrame\n",
    "# print(gdf.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15167e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Add the lulc columns from the pickle file to the geopandas dataframe, using the point geometry as the key\n",
    "# # Ensure geometry column matches the keys in the dictionary\n",
    "# # If the dictionary keys are WKT strings, convert them to geometry objects for comparison\n",
    "# # loaded_geo_lulc_dict = {Point(wkt.loads(k)): v for k, v in loaded_geo_lulc_dict.items()}\n",
    "\n",
    "# # Extract the LULC column names from the dictionary values (assuming uniform structure)\n",
    "# lulc_columns = [f'lulc_{i+1}' for i in range(len(next(iter(loaded_geo_lulc_dict.values()))))]\n",
    "\n",
    "# # Add LULC columns to GeoDataFrame\n",
    "# for idx, geom in enumerate(gdf['geometry']):\n",
    "#     lulc_values = loaded_geo_lulc_dict.get(geom, [None] * len(lulc_columns))\n",
    "#     for col, value in zip(lulc_columns, lulc_values):\n",
    "#         gdf.loc[idx, col] = value\n",
    "\n",
    "# # Display the updated GeoDataFrame\n",
    "# print(gdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3597e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert geometry to WKT format\n",
    "# gdf['geometry'] = gdf['geometry'].apply(lambda geom: geom.wkt)\n",
    "\n",
    "# # Save to CSV\n",
    "# output_csv_path = 'fused_geo_data_june_to_august.csv'\n",
    "# gdf.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# print(f\"GeoDataFrame saved to {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d095277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lulc_1', 'lulc_2', 'lulc_3', 'lulc_4', 'lulc_5', 'lulc_6', 'lulc_7']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import patsy\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Define target and LULC columns\n",
    "gdf = gdf.drop(columns=['lulc_values'])\n",
    "\n",
    "target = 'temperature'  # Replace with your target column name\n",
    "lulc_columns = [col for col in gdf.columns if col.startswith('lulc_')]  # LULC proportions\n",
    "lulc_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4439efd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emaximus/workspace/lsasaf_data_access/.venv/lib/python3.10/site-packages/statsmodels/genmod/families/links.py:13: FutureWarning: The identity link alias is deprecated. Use Identity instead. The identity link alias will be removed after the 0.15.0 release.\n",
      "  warnings.warn(\n",
      "/home/emaximus/workspace/lsasaf_data_access/.venv/lib/python3.10/site-packages/statsmodels/genmod/generalized_linear_model.py:308: DomainWarning: The identity link function does not respect the domain of the Gamma family.\n",
      "  warnings.warn((f\"The {type(family.link).__name__} link function \"\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert 'month' to a categorical variable\n",
    "gdf['month'] = pd.Categorical(gdf['month'])\n",
    "\n",
    "# Convert `hour` to categorical\n",
    "gdf['hour'] = pd.Categorical(gdf['hour'])\n",
    "\n",
    "# Drop rows with missing values\n",
    "gdf = gdf.dropna(subset=[target, 'hour', 'month'] + lulc_columns)\n",
    "\n",
    "# Update the interaction formula to include 'month'\n",
    "# interaction_formula = f\"{target} ~ C(hour) * C(month) * ({' + '.join(lulc_columns)})\"\n",
    "interaction_formula = f\"{target} ~ C(hour) * ({' + '.join(lulc_columns)}) + C(month)\"\n",
    "\n",
    "# Step 2: Split the data into training and testing sets (75-25 split)\n",
    "train_data, test_data = train_test_split(gdf, test_size=0.75, random_state=42)\n",
    "\n",
    "# Step 3: Generate design matrices for train and test sets\n",
    "y_train, X_train = patsy.dmatrices(interaction_formula, data=train_data, return_type='dataframe')\n",
    "y_test, X_test = patsy.dmatrices(interaction_formula, data=test_data, return_type='dataframe')\n",
    "\n",
    "# Step 4: Fit the GLM model on the training data\n",
    "gamma_model = sm.GLM(y_train, X_train, family=sm.families.Gamma(link=sm.families.links.identity()))\n",
    "gamma_results = gamma_model.fit()\n",
    "\n",
    "# Step 5: Display model summary\n",
    "print(gamma_results.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee52772",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = gamma_results.predict(X_test)\n",
    "\n",
    "# Plot observed vs predicted values\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.7, edgecolors='k', label='Data points')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', label='Perfect Fit')\n",
    "plt.xlabel(\"Observed Temperature\")\n",
    "plt.ylabel(\"Predicted Temperature\")\n",
    "plt.title(\"Observed vs Predicted Temperature\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90f1e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the GLM model to a pickle file\n",
    "with open('glm_model.pkl', 'wb') as file:\n",
    "    pickle.dump(gamma_results, file)\n",
    "\n",
    "print(\"GLM model saved as 'glm_model.pkl'\")\n",
    "\n",
    "# Save the model summary to a text file\n",
    "with open('glm_model_summary.txt', 'w') as file:\n",
    "    file.write(gamma_results.summary().as_text())\n",
    "\n",
    "print(\"GLM model summary saved as 'glm_model_summary.txt'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fe5953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure the 'time' column is in datetime format\n",
    "gdf['time'] = pd.to_datetime(gdf['time'])\n",
    "\n",
    "# Sort the GeoDataFrame by time for proper plotting\n",
    "gdf = gdf.sort_values('time')\n",
    "\n",
    "# Plot temperature over time\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(gdf['time'], gdf['temperature'], label='Temperature', color='blue')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Temperature Time Series')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Temperature')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed61a23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure the 'time' column is in datetime format\n",
    "gdf['time'] = pd.to_datetime(gdf['time'])\n",
    "\n",
    "# Extract the month from the 'time' column if not already done\n",
    "gdf['month'] = gdf['time'].dt.month\n",
    "\n",
    "# Filter data for August\n",
    "august_data = gdf[gdf['month'] == 6]\n",
    "\n",
    "# Sort by time\n",
    "august_data = august_data.sort_values('time')\n",
    "\n",
    "# Plot temperature over time for August as points\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(august_data['time'], august_data['temperature'], label='Temperature (August)', color='orange', alpha=0.8)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Temperature Time Series for August (Points)')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Temperature')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cf96dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Compute RMSLE (Root Mean Squared Logarithmic Error)\n",
    "rmsle = np.sqrt(mean_squared_log_error(y_test, y_pred))\n",
    "print(f\"RMSLE: {rmsle:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9711e76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a combined 'month-hour' column for better visualization\n",
    "test_data['month_hour'] = test_data['month'].astype(str) + '-' + test_data['hour'].astype(str)\n",
    "\n",
    "# Add predictions to the test dataset\n",
    "test_data['observed'] = y_test.values\n",
    "test_data['predicted'] = y_pred\n",
    "\n",
    "# Sort by the combined 'month-hour' index for proper plotting\n",
    "test_data = test_data.sort_values(by=['month', 'hour'])\n",
    "\n",
    "# Plot observed vs predicted as a time series\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(test_data['month_hour'], test_data['observed'], label='Observed Temperature', marker='o', linestyle='-', color='blue')\n",
    "plt.plot(test_data['month_hour'], test_data['predicted'], label='Predicted Temperature', marker='x', linestyle='--', color='red')\n",
    "plt.xlabel('Month-Hour')\n",
    "plt.ylabel('Temperature')\n",
    "plt.title('Time Series: Observed vs Predicted Temperature')\n",
    "plt.xticks(rotation=90)  # Rotate x-axis labels for better readability\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
