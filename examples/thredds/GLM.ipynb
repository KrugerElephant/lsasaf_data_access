{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import thredds_lsasaf_utils as tlu\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "from shapely import wkt\n",
    "from shapely.geometry import Point\n",
    "\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.genmod.families import Gaussian\n",
    "from statsmodels.genmod.families.links import Power\n",
    "from statsmodels.genmod.families import Gamma\n",
    "from statsmodels.genmod.families.links import log, identity\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import patsy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fused_data(filename):\n",
    "\n",
    "    # Replace 'your_file.csv' with the path to your CSV file\n",
    "    file_path = filename\n",
    "\n",
    "    # Load the CSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Ensure the CSV contains 'lat' and 'lon' columns\n",
    "    if 'lat' not in df.columns or 'lon' not in df.columns:\n",
    "        raise ValueError(\"The CSV file must contain 'lat' and 'lon' columns\")\n",
    "\n",
    "    # Create a GeoDataFrame\n",
    "    geometry = [Point(xy) for xy in zip(df['lon'], df['lat'])]\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=geometry)\n",
    "\n",
    "    # Set the coordinate reference system (CRS) if known, e.g., WGS84 (EPSG:4326)\n",
    "    gdf.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read data from .csv file\n",
    "gdf = read_fused_data('fused_geo_data_june_to_august.csv')\n",
    "\n",
    "# Define target and LULC columns\n",
    "target = 'temperature'  # Replace with your target column name\n",
    "gdf = gdf.drop(columns=['lulc_values'])\n",
    "lulc_columns = [col for col in gdf.columns if col.startswith('lulc_')]  # LULC proportions\n",
    "\n",
    "# Ensure categorical variables are treated as such\n",
    "gdf['hour'] = gdf['hour'].astype('category')\n",
    "gdf['month'] = gdf['month'].astype('category')\n",
    "gdf['year'] = gdf['year'].astype('category')\n",
    "\n",
    "# Drop rows with missing values\n",
    "gdf = gdf.dropna(subset=[target, 'hour', 'month', 'year'] + lulc_columns)\n",
    "\n",
    "# Update the interaction formula to include 'month'\n",
    "# interaction_formula = f\"{target} ~ C(hour) * C(month) * ({' + '.join(lulc_columns)})\"\n",
    "interaction_formula = f\"{target} ~ C(hour) * ({' + '.join(lulc_columns)}) + C(month)\"\n",
    "\n",
    "# Step 2: Split the data into training and testing sets (75-25 split)\n",
    "train_data, test_data = train_test_split(gdf, test_size=0.75, random_state=42)\n",
    "\n",
    "# Step 3: Generate design matrices for train and test sets\n",
    "y_train, X_train = patsy.dmatrices(interaction_formula, data=train_data, return_type='dataframe')\n",
    "y_test, X_test = patsy.dmatrices(interaction_formula, data=test_data, return_type='dataframe')\n",
    "\n",
    "# Step 4: Fit the GLM model on the training data\n",
    "gamma_model = sm.GLM(y_train, X_train, family=sm.families.Gamma(link=sm.families.links.identity()))\n",
    "gamma_results = gamma_model.fit()\n",
    "\n",
    "# Step 5: Display model summary\n",
    "print(gamma_results.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = gamma_results.predict(X_test)\n",
    "\n",
    "# Plot observed vs predicted values\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.7, edgecolors='k', label='Data points')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', label='Perfect Fit')\n",
    "plt.xlabel(\"Observed Temperature\")\n",
    "plt.ylabel(\"Predicted Temperature\")\n",
    "plt.title(\"Observed vs Predicted Temperature\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "# Save the GLM model to a pickle file\n",
    "with open('glm_model.pkl', 'wb') as file:\n",
    "    pickle.dump(gamma_results, file)\n",
    "\n",
    "print(\"GLM model saved as 'glm_model.pkl'\")\n",
    "\n",
    "# Save the model summary to a text file\n",
    "with open('glm_model_summary.txt', 'w') as file:\n",
    "    file.write(gamma_results.summary().as_text())\n",
    "\n",
    "print(\"GLM model summary saved as 'glm_model_summary.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Compute RMSLE (Root Mean Squared Logarithmic Error)\n",
    "rmsle = np.sqrt(mean_squared_log_error(y_test, y_pred))\n",
    "print(f\"RMSLE: {rmsle:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a combined 'month-hour' column for better visualization\n",
    "test_data['month_hour'] = test_data['month'].astype(str) + '-' + test_data['hour'].astype(str)\n",
    "\n",
    "# Add predictions to the test dataset\n",
    "test_data['observed'] = y_test.values\n",
    "test_data['predicted'] = y_pred\n",
    "\n",
    "# Sort by the combined 'month-hour' index for proper plotting\n",
    "test_data = test_data.sort_values(by=['month', 'hour'])\n",
    "\n",
    "# Plot observed vs predicted as a time series\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(test_data['month_hour'], test_data['observed'], label='Observed Temperature', marker='o', linestyle='-', color='blue')\n",
    "plt.plot(test_data['month_hour'], test_data['predicted'], label='Predicted Temperature', marker='x', linestyle='--', color='red')\n",
    "plt.xlabel('Month-Hour')\n",
    "plt.ylabel('Temperature')\n",
    "plt.title('Time Series: Observed vs Predicted Temperature')\n",
    "plt.xticks(rotation=90)  # Rotate x-axis labels for better readability\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
