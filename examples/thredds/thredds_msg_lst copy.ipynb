{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee75bd4d-0e34-4504-bf98-08e8c8b512d8",
   "metadata": {},
   "source": [
    "<p>Example script to extract 1 month of hourly MLST MSG product over a domain</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211e0dcc-a8c3-4c10-b243-f77fb9d86b01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import thredds_lsasaf_utils as tlu\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f9ee35-4f88-4099-be09-845dcec6390f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change here your user credentials\n",
    "server_user = \"karpagam\"\n",
    "server_passwd = \"chip-chop-2025\"\n",
    "\n",
    "# Change here the product details\n",
    "# Go to https://thredds.lsasvcs.ipma.pt/thredds/catalog/catalog.html\n",
    "# Navigate selecting satelite, product, format, and data to find the product_path and product file name\n",
    "# This is an example for the MSG MLST\n",
    "product_path = \"/MSG/MLST/NETCDF/\"\n",
    "product_fname = \"NETCDF4_LSASAF_MSG_LST_MSG-Disk\"\n",
    "NcvarsLoad = ['LST'] # list of netcdf variables to load from remote files\n",
    "\n",
    "# time period to process\n",
    "dstart = dt.datetime(2024, 6, 1, 0, 0, 0) # start slot\n",
    "dend = dt.datetime(2024, 8, 31, 23, 0, 0)   # end slot\n",
    "product_freq = \"h\" # hourly frequency\n",
    "\n",
    "## Define latitude/longitude domain to load [lat_min,lat_max,lon_min,lon_max,]\n",
    "# LatLonBox = [36, 44,-10, 3] # example for Iberian Peninsula\n",
    "\n",
    "# Define latitude/longitude domain to load [lat_min,lat_max,lon_min,lon_max,]\n",
    "LatLonBox = [41.6899140207028722, 42.0902931428349447, 12.2299337725884012, 12.7300258912577391] # Rome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7686ab-6576-4ab2-a6ec-248b2d46a646",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize product details\n",
    "\n",
    "product = tlu.lsa_product(product_path,product_fname)\n",
    "product.user = server_user\n",
    "product.passwd = server_passwd\n",
    "\n",
    "# list of slots to be processed:\n",
    "slot_list = tlu.gen_slot_list(dstart, dend, product_freq)\n",
    "print(f\"Will load:{len(slot_list)} files: {slot_list[0]} to {slot_list[-1]}\")\n",
    "\n",
    "# Load data\n",
    "ds_full = tlu.load_product_slots_domain(product, slot_list, NcvarsLoad, LatLonBox=LatLonBox)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefba759",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract the data array (assuming the variable name is 'temperature')\n",
    "data_array = ds_full['LST']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fb6472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract the temperature DataArray\n",
    "temperature_da = ds_full['LST']\n",
    "\n",
    "# Step 2: Stack dimensions (combine 'time', 'lat', and 'lon')\n",
    "stacked = temperature_da.stack(points=('time', 'lat', 'lon'))\n",
    "\n",
    "# Step 3: Reset the index and convert to DataFrame\n",
    "df = stacked.reset_index(['time', 'lat', 'lon']).to_dataframe(name='temperature').reset_index(drop=True)\n",
    "\n",
    "# Step 4: Add an 'hour' column 'day', 'month' and 'year'\n",
    "df['hour'] = df['time'].dt.hour\n",
    "df['day'] = df['time'].dt.day\n",
    "df['month'] = df['time'].dt.month\n",
    "df['year'] = df['time'].dt.year\n",
    "\n",
    "# Step 5: Convert to GeoPandas GeoDataFrame\n",
    "geometry = [Point(lon, lat) for lon, lat in zip(df['lon'], df['lat'])]  # Create Point geometries\n",
    "gdf = gpd.GeoDataFrame(df, geometry=geometry, crs=\"EPSG:4326\")  # Set CRS to WGS 84 (EPSG:4326)\n",
    "\n",
    "# Inspect the GeoDataFrame\n",
    "print(gdf.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38609a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c79df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Load the LULC raster and the temperature GeoDataFrame\n",
    "lulc_file = \"ESRI_LULC_2023_Rome.tif\"  # Path to the ESRI LULC TIFF file\n",
    "\n",
    "# Buffer radius: 2.5 km -> 2500 meters\n",
    "buffer_radius = 2500\n",
    "\n",
    "\n",
    "# Step 2: Function to calculate land use proportions\n",
    "def calculate_lulc_proportions(lulc_raster, point, buffer_radius):\n",
    "    \"\"\"\n",
    "    Calculate proportions of LULC categories within a circular buffer around a point.\n",
    "    \"\"\"\n",
    "    # Create a circular buffer around the point (convert to GeoJSON format)\n",
    "    buffer = point.buffer(buffer_radius, resolution=50)  # Buffer with high resolution\n",
    "    geojson_buffer = [buffer.__geo_interface__]  # Convert to GeoJSON format for rasterio.mask\n",
    "\n",
    "    # Mask the LULC raster using the buffer\n",
    "    try:\n",
    "        out_image, out_transform = mask(lulc_raster, geojson_buffer, crop=True)\n",
    "        data = out_image[0]  # Extract the first band\n",
    "        data = data[data > 0]  # Remove invalid or no-data values (assumed to be <= 0)\n",
    "\n",
    "        # Calculate proportions of each LULC category\n",
    "        unique, counts = np.unique(data, return_counts=True)\n",
    "        proportions = {f\"lulc_{int(cat)}\": count / data.size for cat, count in zip(unique, counts)}\n",
    "        return proportions\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing buffer at point {point}: {e}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "# Step 3: Process each point in the GeoDataFrame\n",
    "with rasterio.open(lulc_file) as lulc_raster:\n",
    "    all_proportions = []  # List to store proportions for each point\n",
    "    for idx, row in gdf.iterrows():\n",
    "        point = row.geometry  # Get the point geometry\n",
    "        proportions = calculate_lulc_proportions(lulc_raster, point, buffer_radius)\n",
    "        all_proportions.append(proportions)\n",
    "\n",
    "# Step 4: Merge LULC proportions with the GeoDataFrame\n",
    "proportions_df = pd.DataFrame(all_proportions).fillna(0)  # Replace NaNs with 0 for missing LULC categories\n",
    "gdf = pd.concat([gdf, proportions_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8b843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to categorize hours\n",
    "def categorize_hours(hour):\n",
    "    if 0 <= hour < 7:\n",
    "        return \"early_morning\"\n",
    "    elif 7 <= hour < 10:\n",
    "        return \"morning\"\n",
    "    elif 10 <= hour < 15:\n",
    "        return \"mid_day\"\n",
    "    elif 15 <= hour < 19:\n",
    "        return \"evening\"\n",
    "    elif 19 <= hour < 22:\n",
    "        return \"night\"\n",
    "    elif 22 <= hour <= 23:\n",
    "        return \"late_night\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74350024",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Apply the function to create the new \"hours\" column\n",
    "gdf['hours'] = gdf['hour'].apply(categorize_hours)\n",
    "\n",
    "# Step 3: Verify the result\n",
    "print(\"Sample of DataFrame with the new 'hours' column:\")\n",
    "print(gdf[['hour', 'hours']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cd79d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'hours' column to dummy variables for the GLM\n",
    "hours_dummies = pd.get_dummies(data['hours'], prefix='hours', drop_first=True)\n",
    "\n",
    "# Combine the new dummy variables with the original data\n",
    "X = pd.concat([data[predictors], hours_dummies], axis=1)\n",
    "X = sm.add_constant(X)  # Add an intercept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e752d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Load CSV into a Pandas DataFrame\n",
    "df = pd.read_csv('temperature_data.csv')\n",
    "\n",
    "# Create geometry from latitude and longitude\n",
    "geometry = [Point(xy) for xy in zip(df['lon'], df['lat'])]\n",
    "\n",
    "\n",
    "# Convert to GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(df, geometry=geometry)\n",
    "\n",
    "# Set the Coordinate Reference System (CRS) - assuming WGS84 (EPSG:4326)\n",
    "gdf.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "# Display the GeoDataFrame\n",
    "print(gdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4bacae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gdf.head()\n",
    "gdf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d29cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53e1bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the LULC columns\n",
    "lulc_columns = ['lulc_1', 'lulc_2', 'lulc_4', 'lulc_5', 'lulc_7', 'lulc_8', 'lulc_11']\n",
    "\n",
    "# Create a dictionary with geometry as keys and LULC values as lists\n",
    "geo_lulc_dict = {row['geometry']: row[lulc_columns].to_list() for _, row in gdf.iterrows()}\n",
    "\n",
    "# Display a snippet of the dictionary\n",
    "print(geo_lulc_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f45af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the dictionary as a pickle file\n",
    "with open('landuse_profile.pkl', 'wb') as file:\n",
    "    pickle.dump(geo_lulc_dict, file)\n",
    "\n",
    "print(\"Landuse profile saved as 'landuse_profile.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944769da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pickle file\n",
    "with open('landuse_profile.pkl', 'rb') as file:\n",
    "    loaded_geo_lulc_dict = pickle.load(file)\n",
    "\n",
    "print(\"Loaded landuse profile:\", loaded_geo_lulc_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafcd53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fit the updated GLM\n",
    "model = sm.GLM(Y, X, family=sm.families.Gamma())\n",
    "results = model.fit()\n",
    "\n",
    "print(\"Updated GLM Summary:\")\n",
    "print(results.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babada2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optional: Save as a shapefile or GeoJSON\n",
    "# gdf.to_file(\"temperature_points.geojson\", driver=\"GeoJSON\")\n",
    "# gdf.to_file(\"temperature_points.shp\")\n",
    "\n",
    "# Drop the geometry column and split it into 'lat' and 'lon'\n",
    "gdf['lon'] = gdf.geometry.x  # Extract longitude\n",
    "gdf['lat'] = gdf.geometry.y  # Extract latitude\n",
    "\n",
    "# Drop the geometry column\n",
    "gdf_csv = gdf.drop(columns='geometry')\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "output_csv_path = \"temperature_data.csv\"\n",
    "gdf_csv.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"GeoDataFrame saved as CSV file: {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6130f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ecc2f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.genmod.families import Gaussian\n",
    "from statsmodels.genmod.families.links import Power\n",
    "from statsmodels.genmod.families import Gamma\n",
    "from statsmodels.genmod.families.links import log, identity\n",
    "\n",
    "\n",
    "# Step 1: Convert the 'hour' column to categorical\n",
    "gdf['hour'] = gdf['hour'].astype('category')\n",
    "\n",
    "# Step 2: Prepare the data for GLM\n",
    "# Define the target variable (temperature) and predictors\n",
    "target = 'temperature'\n",
    "predictors = ['hour'] + [col for col in gdf.columns if col.startswith('lulc_')]  # Hour + LULC proportions\n",
    "\n",
    "# Drop rows with missing values in predictors or target\n",
    "data = gdf[[target] + predictors].dropna()\n",
    "\n",
    "# Step 3: Create dummy variables for 'hour'\n",
    "X = pd.get_dummies(data[predictors], drop_first=True)  # Convert 'hour' to dummy variables\n",
    "X = sm.add_constant(X)  # Add an intercept term\n",
    "\n",
    "# Define the dependent variable (Y)\n",
    "Y = data[target]\n",
    "\n",
    "# Print X and Y shapes for verification\n",
    "print(\"Independent Variables (X):\", X.shape)\n",
    "print(\"Dependent Variable (Y):\", Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f78bf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Fit the Generalized Linear Model with Gamma Family\n",
    "# Choose a link function: inverse (default), log, or identity\n",
    "# gamma_family = Gamma()  # Inverse link (default for Gamma)\n",
    "# gamma_family = Gamma(link=log())    # Uncomment for log link\n",
    "gamma_family = Gamma(link=identity())  # Uncomment for identity link\n",
    "\n",
    "# Fit the GLM\n",
    "model = sm.GLM(Y, X, family=gamma_family)\n",
    "results = model.fit()\n",
    "\n",
    "# Step 4: Summarize the model\n",
    "print(\"GLM Model Summary with Gamma Family:\")\n",
    "print(results.summary())\n",
    "\n",
    "# Step 5: Predict new values (optional)\n",
    "data['temperature_predicted'] = results.predict(X)\n",
    "\n",
    "# Save the updated DataFrame with predictions\n",
    "output_file = \"temperature_with_predictions_gamma.csv\"\n",
    "data.to_csv(output_file, index=False)\n",
    "print(f\"Predicted values saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63d8ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdff702",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract observed and predicted temperature values\n",
    "observed = data['temperature']  # Observed temperature\n",
    "predicted = data['temperature_predicted']  # Predicted temperature\n",
    "\n",
    "# Compute RMSE\n",
    "rmse = np.sqrt(mean_squared_error(observed, predicted))\n",
    "\n",
    "# Compute Pearson's Correlation Coefficient\n",
    "correlation, p_value = pearsonr(observed, predicted)\n",
    "\n",
    "# Print results\n",
    "print(\"Model Performance Metrics:\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"Pearson's Correlation Coefficient: {correlation:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a31f9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scatter plot of observed vs. predicted\n",
    "plt.figure(figsize=(8, 6))  # Set figure size\n",
    "plt.scatter(observed, predicted, color='blue', alpha=0.6, edgecolor='k', label='Predicted vs Observed')\n",
    "\n",
    "# Plot a 1:1 line (perfect predictions)\n",
    "min_val = min(observed.min(), predicted.min())\n",
    "max_val = max(observed.max(), predicted.max())\n",
    "plt.plot([min_val, max_val], [min_val, max_val], color='red', linestyle='--', label='1:1 Line')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Observed Temperature')\n",
    "plt.ylabel('Predicted Temperature')\n",
    "plt.title('Observed vs. Predicted Temperature')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4896eee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Fit the Generalized Linear Model\n",
    "model = sm.GLM(Y, X, family=sm.families.Gaussian())  # Gaussian family for continuous response\n",
    "results = model.fit()\n",
    "\n",
    "# Step 4: Summarize the model\n",
    "print(\"GLM Model Summary:\")\n",
    "print(results.summary())\n",
    "\n",
    "# Step 5: Predict new values (optional)\n",
    "data['temperature_predicted'] = results.predict(X)\n",
    "\n",
    "# Extract observed and predicted temperature values\n",
    "observed = data['temperature']  # Observed temperature\n",
    "predicted = data['temperature_predicted']  # Predicted temperature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c3fef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of observed vs. predicted\n",
    "plt.figure(figsize=(8, 6))  # Set figure size\n",
    "plt.scatter(observed, predicted, color='blue', alpha=0.6, edgecolor='k', label='Predicted vs Observed')\n",
    "\n",
    "# Plot a 1:1 line (perfect predictions)\n",
    "min_val = min(observed.min(), predicted.min())\n",
    "max_val = max(observed.max(), predicted.max())\n",
    "plt.plot([min_val, max_val], [min_val, max_val], color='red', linestyle='--', label='1:1 Line')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Observed Temperature')\n",
    "plt.ylabel('Predicted Temperature')\n",
    "plt.title('Observed vs. Predicted Temperature')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
