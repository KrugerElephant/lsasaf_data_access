{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from joblib import load\n",
    "from rasterio.transform import from_origin\n",
    "from rasterio.features import geometry_mask\n",
    "from datetime import datetime, timedelta\n",
    "from rasterio.sample import sample_gen\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "import contextily as ctx  # For OpenStreetMap basemaps\n",
    "\n",
    "def extract_datetime_from_filename(filename):\n",
    "    \"\"\"\n",
    "    Extract year, month, day, and hour from a raster filename containing DOY.\n",
    "\n",
    "    Args:\n",
    "        filename (str): Raster filename with DOY (e.g., 'ECO2LSTE.001_SDS_LST_doy2023156110712_aid0001.tif').\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary with keys 'year', 'month', 'day', 'hour', 'minute', 'second'.\n",
    "    \"\"\"\n",
    "    # Extract the DOY and timestamp information from the filename\n",
    "    parts = filename.split('_doy')\n",
    "    if len(parts) < 2:\n",
    "        raise ValueError(\"Filename does not contain DOY information.\")\n",
    "\n",
    "    doy_part = parts[1].split('_')[0]\n",
    "    year = int(doy_part[:4])\n",
    "    doy = int(doy_part[4:7])\n",
    "    hour = int(doy_part[7:9])\n",
    "    minute = int(doy_part[9:11])\n",
    "    second = int(doy_part[11:13])\n",
    "\n",
    "    # Convert DOY to month and day\n",
    "    date = datetime(year, 1, 1) + timedelta(days=doy - 1)\n",
    "    month = date.month\n",
    "    day = date.day\n",
    "\n",
    "    return {\n",
    "        'year': year,\n",
    "        'month': month,\n",
    "        'day': day,\n",
    "        'hour': hour,\n",
    "        'minute': minute,\n",
    "        'second': second,\n",
    "    }\n",
    "\n",
    "# Helper function to extract data within bounds\n",
    "def extract_raster_data(raster_file, min_lon, max_lon, min_lat, max_lat):\n",
    "    with rasterio.open(raster_file) as src:\n",
    "        transform = src.transform\n",
    "        raster_data = src.read(1)  # Read the first band\n",
    "        raster_data = np.where(raster_data == src.nodata, np.nan, raster_data)  # Replace nodata with NaN\n",
    "        # Calculate row/col indices for the bounding box\n",
    "        min_col = int((min_lon - transform[2]) / transform[0])\n",
    "        max_col = int((max_lon - transform[2]) / transform[0])\n",
    "        min_row = int((max_lat - transform[5]) / transform[4])\n",
    "        max_row = int((min_lat - transform[5]) / transform[4])\n",
    "\n",
    "        # Subset the raster data\n",
    "        subset_data = raster_data[min_row:max_row, min_col:max_col]\n",
    "        extent = (\n",
    "            transform[2] + min_col * transform[0],  # min X (lon)\n",
    "            transform[2] + max_col * transform[0],  # max X (lon)\n",
    "            transform[5] + max_row * transform[4],  # min Y (lat)\n",
    "            transform[5] + min_row * transform[4],  # max Y (lat)\n",
    "        )\n",
    "        return subset_data, extent\n",
    "\n",
    "def get_ecostress_files(directory, keyword=\"LST_doy\"):\n",
    "    \"\"\"Get the list of Ecostress LST files containing the specified keyword.\"\"\"\n",
    "    return [os.path.join(directory, file) for file in os.listdir(directory) if keyword in file]\n",
    "\n",
    "def extract_datetime_from_filename(filename):\n",
    "    \"\"\"\n",
    "    Extract year, month, day, and hour from a raster filename containing DOY.\n",
    "\n",
    "    Args:\n",
    "        filename (str): Raster filename with DOY (e.g., 'ECO2LSTE.001_SDS_LST_doy2023156110712_aid0001.tif').\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary with keys 'year', 'month', 'day', 'hour', 'minute', 'second'.\n",
    "    \"\"\"\n",
    "    # Extract the DOY and timestamp information from the filename\n",
    "    parts = filename.split('_doy')\n",
    "    if len(parts) < 2:\n",
    "        raise ValueError(\"Filename does not contain DOY information.\")\n",
    "\n",
    "    doy_part = parts[1].split('_')[0]\n",
    "    year = int(doy_part[:4])\n",
    "    doy = int(doy_part[4:7])\n",
    "    hour = int(doy_part[7:9])\n",
    "    minute = int(doy_part[9:11])\n",
    "    second = int(doy_part[11:13])\n",
    "\n",
    "    # Convert DOY to month and day\n",
    "    date = datetime(year, 1, 1) + timedelta(days=doy - 1)\n",
    "    month = date.month\n",
    "    day = date.day\n",
    "\n",
    "    return {\n",
    "        'year': year,\n",
    "        'month': month,\n",
    "        'day': day,\n",
    "        'hour': hour,\n",
    "        'minute': minute,\n",
    "        'second': second,\n",
    "    }\n",
    "\n",
    "def get_msg_lst_file(datetime_info, directory=\"../downloads/MSG_2ND\"):\n",
    "    \"\"\"Construct the MSG LST filename for a specific date and time.\"\"\"\n",
    "    return os.path.join(directory, f'LST_{datetime_info[\"year\"]}-{datetime_info[\"month\"]:02d}-{datetime_info[\"day\"]:02d}.gpkg')\n",
    "\n",
    "def filter_gdf_by_datetime(gdf, datetime_info):\n",
    "    \"\"\"Filter GeoDataFrame by year, month, day, and hour.\"\"\"\n",
    "    return gdf[\n",
    "        (gdf['year'] == datetime_info[\"year\"]) &\n",
    "        (gdf['month'] == datetime_info[\"month\"]) &\n",
    "        (gdf['day'] == datetime_info[\"day\"]) &\n",
    "        (gdf['hour'] == datetime_info[\"hour\"])\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_raster_from_points(filtered_gdf, resolution):\n",
    "    \"\"\"Generate a raster from GeoDataFrame points and their LST values.\"\"\"\n",
    "    min_x, min_y, max_x, max_y = filtered_gdf.total_bounds\n",
    "    cols = int((max_x - min_x) / resolution) + 1\n",
    "    rows = int((max_y - min_y) / resolution) + 1\n",
    "\n",
    "    raster = np.full((rows, cols), -9999, dtype=np.float32)  # nodata value\n",
    "    transform = from_origin(min_x, max_y, resolution, resolution)\n",
    "\n",
    "    for x, y, val in zip(filtered_gdf.geometry.x, filtered_gdf.geometry.y, filtered_gdf['temperature']):\n",
    "        col = int((x - min_x) / resolution)\n",
    "        row = int((max_y - y) / resolution)\n",
    "        if 0 <= col < cols and 0 <= row < rows:\n",
    "            raster[row, col] = val\n",
    "\n",
    "    return raster, transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_raster(output_path, raster, transform, crs, nodata=-9999):\n",
    "    \"\"\"Save raster to a GeoTIFF file.\"\"\"\n",
    "    with rasterio.open(\n",
    "        output_path,\n",
    "        'w',\n",
    "        driver='GTiff',\n",
    "        height=raster.shape[0],\n",
    "        width=raster.shape[1],\n",
    "        count=1,\n",
    "        dtype=raster.dtype,\n",
    "        crs=crs,\n",
    "        transform=transform,\n",
    "        nodata=nodata\n",
    "    ) as dst:\n",
    "        dst.write(raster, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree\n",
    "import numpy as np\n",
    "\n",
    "def update_predictions(lu_gdf, coarse_gdf, predictors, loaded_model):\n",
    "    \"\"\"Update predictions in the land-use GeoDataFrame.\"\"\"\n",
    "    coords = np.array([(point.x, point.y) for point in lu_gdf.geometry])\n",
    "    coarse_coords = np.array([(point.x, point.y) for point in coarse_gdf.geometry])\n",
    "    coarse_temps = coarse_gdf['temperature'].values\n",
    "\n",
    "    # Build a spatial index for the coarse grid points\n",
    "    tree = cKDTree(coarse_coords)\n",
    "    _, indices = tree.query(coords, k=1)  # Find the nearest neighbor\n",
    "\n",
    "    # Get the temperature from the closest coarse_gdf point\n",
    "    lu_gdf['msg_lst_temperature'] = coarse_temps[indices]\n",
    "\n",
    "    # Filter out rows with nodata temperature values\n",
    "    lu_gdf_filtered = lu_gdf[lu_gdf['msg_lst_temperature'] != -9999].copy()\n",
    "    lu_gdf_filtered['msg_lst_temperature'] += 273.15  # Convert to Kelvin\n",
    "    lu_gdf_filtered['month'] = datetime_info[\"month\"]\n",
    "    lu_gdf_filtered['hour'] = datetime_info[\"hour\"]\n",
    "\n",
    "    # If all predictors are 0 then drop the row\n",
    "    lu_gdf_filtered = lu_gdf_filtered[(lu_gdf_filtered[predictors[:-2]] != 0).any(axis=1)].copy()\n",
    "\n",
    "    # Predict LST\n",
    "    lu_gdf_filtered['temperature'] = loaded_model.predict(lu_gdf_filtered[predictors])\n",
    "\n",
    "    lu_gdf.loc[lu_gdf_filtered.index, 'temperature'] = lu_gdf_filtered['temperature']\n",
    "\n",
    "    # Convert to Celsius\n",
    "    lu_gdf.loc[lu_gdf['temperature'] != -9999, 'temperature'] -= 273.15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def update_predictions(lu_gdf, src, predictors, loaded_model):\n",
    "#     \"\"\"Update predictions in the land-use GeoDataFrame.\"\"\"\n",
    "#     coords = [(point.x, point.y) for point in lu_gdf.geometry]\n",
    "#     lu_gdf['msg_lst_temperature'] = [\n",
    "#         val[0] if val else -9999 for val in sample_gen(src, coords)\n",
    "#     ]\n",
    "\n",
    "#     lu_gdf_filtered = lu_gdf[lu_gdf['msg_lst_temperature'] != -9999].copy()\n",
    "#     lu_gdf_filtered['msg_lst_temperature'] += 273.15\n",
    "#     lu_gdf_filtered['month'] = datetime_info[\"month\"]\n",
    "#     lu_gdf_filtered['hour'] = datetime_info[\"hour\"]\n",
    "\n",
    "#     # If all predictors are 0 then drop the row\n",
    "#     lu_gdf_filtered = lu_gdf_filtered[(lu_gdf_filtered[predictors[:-2]] != 0).any(axis=1)].copy()\n",
    "\n",
    "#     # Predict LST\n",
    "#     lu_gdf_filtered['temperature'] = loaded_model.predict(lu_gdf_filtered[predictors])\n",
    "\n",
    "#     lu_gdf.loc[lu_gdf_filtered.index, 'temperature'] = lu_gdf_filtered['temperature']\n",
    "\n",
    "#     # Convert to Celsius\n",
    "#     lu_gdf.loc[lu_gdf['temperature'] != -9999, 'temperature'] -= 273.15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecostress_dir = \"../downloads/ECOSTRESS_LST\"\n",
    "ecostress_files = get_ecostress_files(ecostress_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecostress_files = ecostress_files[len(ecostress_files)-2:len(ecostress_files)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../downloads/ECOSTRESS_LST/ECO2LSTE.001_SDS_LST_doy2024217103456_aid0001.tif']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecostress_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Load the trained model\n",
    "model_filename = \"random_forest_model.pkl\"\n",
    "loaded_model = load(model_filename)\n",
    "\n",
    "# Step 2: Load land use profiles for the geometry points in the LU profile file\n",
    "lu_profile_file = \"../lu_profiles/rome_2023_landuse_profile_35m.gpkg\"\n",
    "lu_gdf = gpd.read_file(lu_profile_file)\n",
    "\n",
    "predictors = ['trees', 'water', 'crop', 'built_area', 'range_land', 'msg_lst_temperature', 'month', 'hour']\n",
    "coarse_resolution = 0.05 # Approximately 5000 meters\n",
    "fine_resolution = 0.0006309  # Approximately 70 meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../downloads/MSG_2ND/LST_2024-08-04.gpkg\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
      "[10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_193786/2266626641.py:15: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  avg_distance = filtered_gdf.geometry.apply(lambda point: point.distance(filtered_gdf.geometry.unary_union.centroid)).mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downscaled raster saved: ../lst_rasters/MSG-LST-DOWNSCALED-2024-08-04-10.tif\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for ecostress_raster_file in ecostress_files:\n",
    "\n",
    "    # Extract date and time info from filename\n",
    "    datetime_info = extract_datetime_from_filename(os.path.basename(ecostress_raster_file))\n",
    "\n",
    "    # Create MSG LST data file name for the extracted date and hour\n",
    "    msg_lst_filename = get_msg_lst_file(datetime_info)\n",
    "\n",
    "    # Checj if the file exists\n",
    "    if not os.path.exists(msg_lst_filename):\n",
    "        continue\n",
    "\n",
    "    print(msg_lst_filename)\n",
    "\n",
    "    # Read the file\n",
    "    gdf = gpd.read_file(msg_lst_filename)\n",
    "\n",
    "    print(gdf[\"hour\"].unique())\n",
    "    # Filter by the hour\n",
    "    filtered_gdf = filter_gdf_by_datetime(gdf, datetime_info)\n",
    "\n",
    "    print(filtered_gdf[\"hour\"].unique())\n",
    "\n",
    "    if filtered_gdf.empty:\n",
    "        print(\"No data found for the specified date and time.\")\n",
    "        continue\n",
    "\n",
    "    coarse_resolution = 0.05\n",
    "    raster, transform = create_raster_from_points(filtered_gdf, coarse_resolution)\n",
    "    output_raster = f'../lst_rasters/MSG-LST-{datetime_info[\"year\"]}-{datetime_info[\"month\"]:02d}-{datetime_info[\"day\"]:02d}-{datetime_info[\"hour\"]:02d}.tif'\n",
    "    save_raster(output_raster, raster, transform, filtered_gdf.crs)\n",
    "\n",
    "    update_predictions(lu_gdf, filtered_gdf, predictors, loaded_model)\n",
    "\n",
    "    # with rasterio.open(output_raster) as src:\n",
    "    #     update_predictions(lu_gdf, src, predictors, loaded_model)\n",
    "\n",
    "    predicted_raster, predicted_transorm = create_raster_from_points(lu_gdf, fine_resolution)\n",
    "\n",
    "    output_predicted_raster = f'../lst_rasters/MSG-LST-DOWNSCALED-{datetime_info[\"year\"]}-{datetime_info[\"month\"]:02d}-{datetime_info[\"day\"]:02d}-{datetime_info[\"hour\"]:02d}.tif'\n",
    "    save_raster(output_predicted_raster, predicted_raster, predicted_transorm, lu_gdf.crs)\n",
    "\n",
    "    print(f\"Downscaled raster saved: {output_predicted_raster}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../lst_rasters/MSG-LST-2024-08-04-10.tif, ../lst_rasters/MSG-LST-DOWNSCALED-2024-08-04-10.tif\n",
      "zero-size array to reduction operation fmin which has no identity\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Define the extent (bounding box) to extract (in geographic coordinates)\n",
    "min_lon, max_lon = 12.53514, 12.58\n",
    "min_lat, max_lat = 41.84959, 41.90\n",
    "\n",
    "for ecostress_raster_file in ecostress_files:\n",
    "\n",
    "    datetime_info = extract_datetime_from_filename(os.path.basename(ecostress_raster_file))\n",
    "    msg_lst_filename = get_msg_lst_file(datetime_info)\n",
    "\n",
    "    # Load the coarse, fine, and Ecostress raster files\n",
    "    coarse_raster_file = f'../lst_rasters/MSG-LST-{datetime_info[\"year\"]}-{datetime_info[\"month\"]:02d}-{datetime_info[\"day\"]:02d}-{datetime_info[\"hour\"]:02d}.tif'\n",
    "\n",
    "    if not os.path.exists(coarse_raster_file):\n",
    "        continue\n",
    "\n",
    "    fine_raster_file = f'../lst_rasters/MSG-LST-DOWNSCALED-{datetime_info[\"year\"]}-{datetime_info[\"month\"]:02d}-{datetime_info[\"day\"]:02d}-{datetime_info[\"hour\"]:02d}.tif'\n",
    "    if not os.path.exists(fine_raster_file):\n",
    "        continue\n",
    "\n",
    "    print(f'{coarse_raster_file}, {fine_raster_file}')\n",
    "\n",
    "    # Extract the subsets for all rasters\n",
    "    coarse_data, coarse_extent = extract_raster_data(coarse_raster_file, min_lon, max_lon, min_lat, max_lat)\n",
    "    fine_data, fine_extent = extract_raster_data(fine_raster_file, min_lon, max_lon, min_lat, max_lat)\n",
    "    ecostress_data, ecostress_extent = extract_raster_data(ecostress_raster_file, min_lon, max_lon, min_lat, max_lat)\n",
    "\n",
    "    # Mask temperatures less than 5°C by setting them to NaN\n",
    "    ecostress_data = np.where(\n",
    "        (ecostress_data * 0.02 - 273.15) < 20,  # Check if temperature < 5°C\n",
    "        np.nan,                                # Set to NaN if condition is met\n",
    "        (ecostress_data * 0.02) - 273.15       # Otherwise, scale and convert to Celsius\n",
    "    )\n",
    "\n",
    "    # Mask temperatures greater than 50°C by setting them to NaN\n",
    "    ecostress_data = np.where(ecostress_data > 50, np.nan, ecostress_data) # Set to NaN if condition is met\n",
    "\n",
    "    try:\n",
    "\n",
    "        if np.isnan(np.nanmin(coarse_data)) or np.isnan(np.nanmin(fine_data)):\n",
    "            continue\n",
    "\n",
    "        print(f'{np.nanmin(coarse_data)}, {np.nanmin(fine_data)}, {np.nanmin(ecostress_data)}')\n",
    "        print(f'{np.nanmax(coarse_data)}, {np.nanmax(fine_data)}, {np.nanmax(ecostress_data)}')\n",
    "\n",
    "        # Ensure both arrays have the same shape by slicing the larger one\n",
    "        if fine_data.shape != ecostress_data.shape:\n",
    "            # Find the minimum row and column sizes\n",
    "            min_rows = min(fine_data.shape[0], ecostress_data.shape[0])\n",
    "            min_cols = min(fine_data.shape[1], ecostress_data.shape[1])\n",
    "\n",
    "            # Slice the arrays to the same size\n",
    "            fine_data = fine_data[:min_rows, :min_cols]\n",
    "            ecostress_data = ecostress_data[:min_rows, :min_cols]\n",
    "\n",
    "        # Calculate temperature difference between fine and Ecostress\n",
    "        temperature_diff = fine_data - ecostress_data\n",
    "\n",
    "        # Set the difference to 0 if either fine_data or ecostress_data contains NaN\n",
    "        temperature_diff = np.where(\n",
    "            np.isnan(fine_data) | np.isnan(ecostress_data),  # Condition: Either value is NaN\n",
    "            0,                                              # Set to 0\n",
    "            temperature_diff                                # Otherwise, keep the difference\n",
    "        )\n",
    "\n",
    "        # Define temperature bins (1 degree Celsius each)\n",
    "        temp_min = min(np.nanmin(coarse_data), np.nanmin(fine_data), np.nanmin(ecostress_data))\n",
    "        temp_max = max(np.nanmax(coarse_data), np.nanmax(fine_data), np.nanmax(ecostress_data))\n",
    "        bins = np.arange(np.floor(temp_min), np.ceil(temp_max) + 1, 1)  # 1-degree bins\n",
    "\n",
    "        from matplotlib.colors import TwoSlopeNorm\n",
    "\n",
    "        # Define temperature difference colormap (e.g., shades of blue to red)\n",
    "        cmap_diff = plt.cm.coolwarm\n",
    "\n",
    "        # Create a TwoSlopeNorm to center the color scale at 0\n",
    "        norm_diff = TwoSlopeNorm(vmin=np.nanmin(temperature_diff), vmax=np.nanmax(temperature_diff), vcenter=0)\n",
    "\n",
    "        # Create a standard colormap for the other plots (using 'viridis')\n",
    "        cmap_standard = plt.cm.viridis\n",
    "        norm_standard = BoundaryNorm(bins, cmap_standard.N)\n",
    "\n",
    "        # Plot the maps\n",
    "        fig, axes = plt.subplots(4, 1, figsize=(10, 16), sharex=True, sharey=True)\n",
    "\n",
    "        # Plot the coarse raster\n",
    "        ax = axes[0]\n",
    "        im = ax.imshow(coarse_data, cmap=cmap_standard, norm=norm_standard, extent=coarse_extent, interpolation='nearest')\n",
    "        ax.set_title(\"Coarse Resolution LST\")\n",
    "        ax.set_xlabel(\"Longitude\")\n",
    "        ax.set_ylabel(\"Latitude\")\n",
    "        plt.colorbar(im, ax=ax, label=\"Temperature (°C)\", ticks=bins)\n",
    "\n",
    "        # Plot the fine raster\n",
    "        ax = axes[1]\n",
    "        im = ax.imshow(fine_data, cmap=cmap_standard, norm=norm_standard, extent=fine_extent, interpolation='nearest')\n",
    "        ax.set_title(\"Fine Resolution LST\")\n",
    "        ax.set_xlabel(\"Longitude\")\n",
    "        ax.set_ylabel(\"Latitude\")\n",
    "        plt.colorbar(im, ax=ax, label=\"Temperature (°C)\", ticks=bins)\n",
    "\n",
    "        # Plot the Ecostress raster\n",
    "        ax = axes[2]\n",
    "        im = ax.imshow(ecostress_data, cmap=cmap_standard, norm=norm_standard, extent=ecostress_extent, interpolation='nearest')\n",
    "        ax.set_title(\"Ecostress LST\")\n",
    "        ax.set_xlabel(\"Longitude\")\n",
    "        ax.set_ylabel(\"Latitude\")\n",
    "        plt.colorbar(im, ax=ax, label=\"Temperature (°C)\", ticks=bins)\n",
    "\n",
    "        # Plot the difference (fine - ecostress) using cmap_diff (blue to red)\n",
    "        ax = axes[3]\n",
    "        im = ax.imshow(temperature_diff, cmap=cmap_diff, norm=norm_diff, extent=fine_extent, interpolation='nearest')\n",
    "        ax.set_title(\"Difference (Fine - Ecostress) LST\")\n",
    "        ax.set_xlabel(\"Longitude\")\n",
    "        ax.set_ylabel(\"Latitude\")\n",
    "        plt.colorbar(im, ax=ax, label=\"Temperature Difference (°C)\")\n",
    "\n",
    "        plot_filename = f'../LST_MAP_COMPARISON/LST-VILLA-DI-SANTIS-{datetime_info[\"year\"]}-{datetime_info[\"month\"]:02d}-{datetime_info[\"day\"]:02d}-{datetime_info[\"hour\"]:02d}.png'\n",
    "\n",
    "        # Final layout adjustments\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save the plot\n",
    "        plt.savefig(plot_filename)\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "print(\"Done\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
